{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8820e4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d977a8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 7, 1, 2, 5, 6, 4, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = torch.tensor([0, 7, 1, 2, 5, 6, 4, 3])\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3612c0cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "embed = nn.Embedding(num_embeddings=10, embedding_dim=16)\n",
    "embedded_sentence = embed(sentence).detach()\n",
    "embedded_sentence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b8efaae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9.7601,  1.7326,  4.7543, -1.3587,  0.4752, -1.6717,  1.0227, -0.1286],\n",
       "        [ 1.7326, 16.0787,  9.0642, -0.3370,  1.1368,  1.1972,  1.6485, -1.2789],\n",
       "        [ 4.7543,  9.0642, 22.6615, -0.8519,  7.7799,  2.7483, -0.6832,  1.6236],\n",
       "        [-1.3587, -0.3370, -0.8519, 13.9473, -1.4198, 10.9659, -0.5887,  2.3869],\n",
       "        [ 0.4752,  1.1368,  7.7799, -1.4198, 13.7511, -6.8568, -2.5114, -3.3468],\n",
       "        [-1.6717,  1.1972,  2.7483, 10.9659, -6.8568, 24.6738, -3.8294,  4.9581],\n",
       "        [ 1.0227,  1.6485, -0.6832, -0.5887, -2.5114, -3.8294, 15.8691,  2.0269],\n",
       "        [-0.1286, -1.2789,  1.6236,  2.3869, -3.3468,  4.9581,  2.0269, 18.7382]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omega = torch.empty(8, 8)\n",
    "for i, x_i in enumerate(embedded_sentence):\n",
    "     for j, x_j in enumerate(embedded_sentence):\n",
    "         omega[i, j] = torch.dot(x_i, x_j)\n",
    "omega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad1eeb64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9.7601,  1.7326,  4.7543, -1.3587,  0.4752, -1.6717,  1.0227, -0.1286],\n",
       "        [ 1.7326, 16.0787,  9.0642, -0.3370,  1.1368,  1.1972,  1.6485, -1.2789],\n",
       "        [ 4.7543,  9.0642, 22.6615, -0.8519,  7.7799,  2.7483, -0.6832,  1.6236],\n",
       "        [-1.3587, -0.3370, -0.8519, 13.9473, -1.4198, 10.9659, -0.5887,  2.3869],\n",
       "        [ 0.4752,  1.1368,  7.7799, -1.4198, 13.7511, -6.8568, -2.5114, -3.3468],\n",
       "        [-1.6717,  1.1972,  2.7483, 10.9659, -6.8568, 24.6738, -3.8294,  4.9581],\n",
       "        [ 1.0227,  1.6485, -0.6832, -0.5887, -2.5114, -3.8294, 15.8691,  2.0269],\n",
       "        [-0.1286, -1.2789,  1.6236,  2.3869, -3.3468,  4.9581,  2.0269, 18.7382]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omega_mat = embedded_sentence.matmul(embedded_sentence.T)\n",
    "omega_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec9a7ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(omega, omega_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b22fe35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "attention_weights = F.softmax(omega, dim=1)\n",
    "attention_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48ea3d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33370772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_j: tensor([ 0.3374, -0.1778, -0.3035, -0.5880,  0.3486,  0.6603, -0.2196, -0.3792,\n",
      "         0.7671, -1.1925,  0.6984, -1.4097,  0.1794,  1.8951,  0.4954,  0.2692])\n",
      "context_vec_2: tensor([ 1.9828e-07, -1.0448e-07, -1.7839e-07, -3.4559e-07,  2.0488e-07,\n",
      "         3.8810e-07, -1.2909e-07, -2.2285e-07,  4.5085e-07, -7.0086e-07,\n",
      "         4.1044e-07, -8.2853e-07,  1.0543e-07,  1.1138e-06,  2.9119e-07,\n",
      "         1.5822e-07])\n",
      "x_j: tensor([-9.4053e-01, -4.6806e-01,  1.0322e+00, -2.8300e-01,  4.9275e-01,\n",
      "        -1.4078e-02, -2.7466e-01, -7.6409e-01,  1.3966e+00, -9.9491e-01,\n",
      "        -1.5822e-03,  1.2471e+00, -7.7105e-02,  1.2774e+00, -1.4596e+00,\n",
      "        -2.1595e+00])\n",
      "context_vec_2: tensor([-9.3968e-01, -4.6764e-01,  1.0313e+00, -2.8275e-01,  4.9231e-01,\n",
      "        -1.4065e-02, -2.7442e-01, -7.6340e-01,  1.3953e+00, -9.9402e-01,\n",
      "        -1.5804e-03,  1.2460e+00, -7.7035e-02,  1.2762e+00, -1.4583e+00,\n",
      "        -2.1576e+00])\n",
      "x_j: tensor([-0.0770, -1.0205, -0.1690,  0.9178,  1.5810,  1.3010,  1.2753, -0.2010,\n",
      "         0.4965, -1.5723,  0.9666, -1.1481, -1.1589,  0.3255, -0.6315, -2.8400])\n",
      "context_vec_2: tensor([-9.3975e-01, -4.6856e-01,  1.0311e+00, -2.8192e-01,  4.9373e-01,\n",
      "        -1.2897e-02, -2.7327e-01, -7.6358e-01,  1.3958e+00, -9.9543e-01,\n",
      "        -7.1252e-04,  1.2449e+00, -7.8076e-02,  1.2765e+00, -1.4589e+00,\n",
      "        -2.1601e+00])\n",
      "x_j: tensor([-1.3250,  0.1784, -2.1338,  1.0524, -0.3885, -0.9343, -0.4991, -1.0867,\n",
      "         0.8805,  1.5542,  0.6266, -0.1755,  0.0983, -0.0935,  0.2662, -0.5850])\n",
      "context_vec_2: tensor([-9.3975e-01, -4.6856e-01,  1.0311e+00, -2.8192e-01,  4.9373e-01,\n",
      "        -1.2897e-02, -2.7327e-01, -7.6358e-01,  1.3958e+00, -9.9543e-01,\n",
      "        -7.1247e-04,  1.2449e+00, -7.8076e-02,  1.2765e+00, -1.4589e+00,\n",
      "        -2.1601e+00])\n",
      "x_j: tensor([ 0.2553, -0.5496,  1.0042,  0.8272, -0.3948,  0.4892, -0.2168, -1.7472,\n",
      "        -1.6025, -1.0764,  0.9031, -0.7218, -0.5951, -0.7112,  0.6230, -1.3729])\n",
      "context_vec_2: tensor([-9.3975e-01, -4.6856e-01,  1.0311e+00, -2.8192e-01,  4.9373e-01,\n",
      "        -1.2897e-02, -2.7327e-01, -7.6359e-01,  1.3958e+00, -9.9543e-01,\n",
      "        -7.1218e-04,  1.2449e+00, -7.8076e-02,  1.2765e+00, -1.4589e+00,\n",
      "        -2.1601e+00])\n",
      "x_j: tensor([-2.2150, -1.3193, -2.0915,  0.9629, -0.0319, -0.4790,  0.7668,  0.0275,\n",
      "         1.9929,  1.3708, -0.5009, -0.2793, -2.0628,  0.0064, -0.9896,  0.7016])\n",
      "context_vec_2: tensor([-9.3975e-01, -4.6856e-01,  1.0311e+00, -2.8192e-01,  4.9373e-01,\n",
      "        -1.2897e-02, -2.7327e-01, -7.6359e-01,  1.3958e+00, -9.9543e-01,\n",
      "        -7.1235e-04,  1.2449e+00, -7.8076e-02,  1.2765e+00, -1.4589e+00,\n",
      "        -2.1601e+00])\n",
      "x_j: tensor([ 0.5146,  0.9938, -0.2587, -1.0826, -0.0444,  1.6236, -2.3229,  1.0878,\n",
      "         0.6716,  0.6933, -0.9487, -0.0765, -0.1526,  0.1167,  0.4403, -1.4465])\n",
      "context_vec_2: tensor([-9.3975e-01, -4.6856e-01,  1.0311e+00, -2.8192e-01,  4.9373e-01,\n",
      "        -1.2896e-02, -2.7327e-01, -7.6358e-01,  1.3958e+00, -9.9543e-01,\n",
      "        -7.1287e-04,  1.2449e+00, -7.8077e-02,  1.2765e+00, -1.4589e+00,\n",
      "        -2.1601e+00])\n",
      "x_j: tensor([ 0.8768,  1.6221, -1.4779,  1.1331, -1.2203,  1.3139,  1.0533,  0.1388,\n",
      "         2.2473, -0.8036, -0.2808,  0.7697, -0.6596, -0.7979,  0.1838,  0.2293])\n",
      "context_vec_2: tensor([-9.3975e-01, -4.6856e-01,  1.0311e+00, -2.8192e-01,  4.9373e-01,\n",
      "        -1.2896e-02, -2.7327e-01, -7.6358e-01,  1.3958e+00, -9.9543e-01,\n",
      "        -7.1287e-04,  1.2449e+00, -7.8077e-02,  1.2765e+00, -1.4589e+00,\n",
      "        -2.1601e+00])\n"
     ]
    }
   ],
   "source": [
    "x_2 = embedded_sentence[1, :]\n",
    "context_vec_2 = torch.zeros(x_2.shape)\n",
    "for j in range(8):\n",
    "    x_j = embedded_sentence[j, :]\n",
    "    print('x_j:', x_j)\n",
    "    context_vec_2 += attention_weights[1, j] * x_j\n",
    "    print('context_vec_2:', context_vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81c9e3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.3420e-01, -1.8324e-01, -3.0218e-01, -5.7772e-01,  3.5662e-01,\n",
       "          6.6452e-01, -2.0998e-01, -3.7798e-01,  7.6537e-01, -1.1946e+00,\n",
       "          6.9960e-01, -1.4067e+00,  1.7021e-01,  1.8838e+00,  4.8729e-01,\n",
       "          2.4730e-01],\n",
       "        [-9.3975e-01, -4.6856e-01,  1.0311e+00, -2.8192e-01,  4.9373e-01,\n",
       "         -1.2896e-02, -2.7327e-01, -7.6358e-01,  1.3958e+00, -9.9543e-01,\n",
       "         -7.1287e-04,  1.2449e+00, -7.8077e-02,  1.2765e+00, -1.4589e+00,\n",
       "         -2.1601e+00],\n",
       "        [-7.7021e-02, -1.0205e+00, -1.6895e-01,  9.1776e-01,  1.5810e+00,\n",
       "          1.3010e+00,  1.2753e+00, -2.0095e-01,  4.9647e-01, -1.5723e+00,\n",
       "          9.6657e-01, -1.1481e+00, -1.1589e+00,  3.2547e-01, -6.3151e-01,\n",
       "         -2.8400e+00],\n",
       "        [-1.3679e+00,  1.0614e-01, -2.1317e+00,  1.0480e+00, -3.7127e-01,\n",
       "         -9.1234e-01, -4.3802e-01, -1.0329e+00,  9.3425e-01,  1.5453e+00,\n",
       "          5.7218e-01, -1.8049e-01, -6.0453e-03, -8.8691e-02,  2.0559e-01,\n",
       "         -5.2292e-01],\n",
       "        [ 2.5444e-01, -5.5082e-01,  1.0012e+00,  8.2746e-01, -3.8978e-01,\n",
       "          4.9129e-01, -2.1302e-01, -1.7432e+00, -1.5972e+00, -1.0776e+00,\n",
       "          9.0331e-01, -7.2292e-01, -5.9652e-01, -7.0857e-01,  6.1977e-01,\n",
       "         -1.3766e+00],\n",
       "        [-2.2150e+00, -1.3193e+00, -2.0915e+00,  9.6285e-01, -3.1862e-02,\n",
       "         -4.7896e-01,  7.6681e-01,  2.7467e-02,  1.9929e+00,  1.3708e+00,\n",
       "         -5.0087e-01, -2.7928e-01, -2.0628e+00,  6.3744e-03, -9.8955e-01,\n",
       "          7.0161e-01],\n",
       "        [ 5.1463e-01,  9.9376e-01, -2.5873e-01, -1.0825e+00, -4.4383e-02,\n",
       "          1.6236e+00, -2.3229e+00,  1.0878e+00,  6.7156e-01,  6.9329e-01,\n",
       "         -9.4872e-01, -7.6506e-02, -1.5264e-01,  1.1674e-01,  4.4026e-01,\n",
       "         -1.4465e+00],\n",
       "        [ 8.7683e-01,  1.6221e+00, -1.4779e+00,  1.1331e+00, -1.2203e+00,\n",
       "          1.3139e+00,  1.0533e+00,  1.3880e-01,  2.2473e+00, -8.0363e-01,\n",
       "         -2.8084e-01,  7.6967e-01, -6.5956e-01, -7.9793e-01,  1.8383e-01,\n",
       "          2.2935e-01]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vectors = torch.matmul(attention_weights, embedded_sentence)\n",
    "context_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26060d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(context_vectors[1], context_vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2c0a9c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "d = embedded_sentence.shape[1]\n",
    "U_query = torch.rand(d, d)\n",
    "U_key = torch.rand(d, d)\n",
    "U_value = torch.rand(d, d)\n",
    "\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "329108e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-1.2403, -2.9754, -0.2894, -0.4004, -2.9578, -0.2939, -0.2266, -3.6482,\n",
       "         -2.6450, -0.9536, -1.1116,  1.1717, -2.2671, -0.7874, -2.0140, -1.6652]),\n",
       " torch.Size([16]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_2 = embedded_sentence[1]\n",
    "query_2 = U_query.matmul(x_2)\n",
    "query_2, query_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdb99ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-1.2952,  0.5116, -0.5343, -2.1730, -0.5293, -0.4932, -2.0952, -0.5830,\n",
       "         -0.2856,  0.1277,  0.6852, -1.5782, -0.9960, -2.3458, -0.4437, -0.5510]),\n",
       " tensor([ 0.6654, -1.1762,  0.2593, -1.2616, -1.1232, -1.1314, -0.8960, -0.0376,\n",
       "         -3.1714, -0.4293, -1.6761, -0.0262, -0.6826, -0.7709,  0.5206, -2.5693]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_2 = U_key.matmul(x_2)\n",
    "value_2 = U_value.matmul(x_2)\n",
    "key_2, value_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44fa2df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7665, -1.1306,  0.0167,  1.3456, -0.0111,  0.2577,  0.3018,  0.5771,\n",
       "          0.8287, -0.3224,  0.9979, -1.3807,  0.7953,  0.3018,  1.1813,  1.3559],\n",
       "        [-1.2403, -2.9754, -0.2894, -0.4004, -2.9578, -0.2939, -0.2266, -3.6482,\n",
       "         -2.6450, -0.9536, -1.1116,  1.1717, -2.2671, -0.7874, -2.0140, -1.6652],\n",
       "        [-1.4620, -2.9039, -2.9815,  0.1616, -1.7143, -3.4239, -1.4447, -2.2414,\n",
       "         -3.0720, -3.0587,  1.1979,  0.2866, -0.5552, -0.0643, -1.3262, -0.3223],\n",
       "        [ 0.0758, -1.2134, -2.7353, -1.2504, -2.3630, -1.7872, -2.4223, -1.3309,\n",
       "          0.0371,  0.4128, -0.2362, -1.7722, -0.9576, -0.6908, -1.9191, -0.0077],\n",
       "        [-1.0274, -3.9126, -2.1115, -1.1729, -2.0862, -4.8391, -1.5899, -2.5706,\n",
       "         -3.0113, -3.2927, -4.0568, -0.3453, -3.0388, -2.1831, -2.6464, -2.5228],\n",
       "        [-0.6838, -2.4960, -4.3936, -3.7471, -2.7305, -2.1619, -5.9295, -3.5328,\n",
       "         -1.5616,  0.2982, -0.4995, -2.9656, -1.4150, -1.2241, -2.2443, -2.1584],\n",
       "        [ 0.8982,  0.1030,  0.4428,  0.6328, -1.7003,  1.3489, -0.3082, -0.5900,\n",
       "         -0.9257, -0.7688,  1.8828, -1.6065, -0.8011, -0.4114, -0.6116,  1.3902],\n",
       "        [ 2.9258,  2.5598,  2.3612,  0.9851,  3.3478,  2.5134,  1.4786,  2.4595,\n",
       "          3.2942,  2.1628,  4.1394,  0.7536,  2.8714,  3.5802, -0.2554,  2.9326]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = embedded_sentence.matmul(U_query.T)\n",
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "831c91ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys1 = U_key.matmul(embedded_sentence.T).T\n",
    "values1 = U_value.matmul(embedded_sentence.T).T\n",
    "# print(keys, values)\n",
    "\n",
    "keys = embedded_sentence.matmul(U_key.T)  # embedded_sentence (L, d), U_value (16x16), для перемножения нужно чтобы было (16хА) и (Ах8)\n",
    "values = embedded_sentence.matmul(U_value.T)\n",
    "torch.allclose(keys1, keys), torch.allclose(values1, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de521d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09983b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -0.7569,  -3.7951,  -7.9465, -10.0615, -12.1732, -12.8006,   4.1644,\n",
       "           6.3346],\n",
       "        [-25.1623,   9.3602,  14.3667,  32.1482,  53.8976,  46.6626,  -1.2131,\n",
       "         -32.9392],\n",
       "        [-28.8096,  10.9046,  14.4355,  23.8255,  52.7999,  41.3237,   1.5884,\n",
       "         -35.1890],\n",
       "        [-15.5115,  17.5500,  19.8771,  21.5002,  42.0597,  35.2061,  -0.5541,\n",
       "         -25.9203],\n",
       "        [-36.3682,  20.2438,  27.1240,  49.8610,  84.9364,  85.7472,   5.8265,\n",
       "         -69.9103],\n",
       "        [-34.6901,  38.3814,  42.0269,  48.1298,  92.0512,  74.9869,  -6.6510,\n",
       "         -65.5576],\n",
       "        [ -1.1880,   3.7619,  -5.6129,  -6.8690,   6.3126, -13.3452,  -1.3225,\n",
       "          -6.2390],\n",
       "        [ 31.8297, -25.2041, -25.3536, -57.8440, -79.4676, -85.3054, -10.5390,\n",
       "          64.5980]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = queries @ keys.T\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5bacf7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8.9701e-02, 4.1968e-02, 1.4866e-02, 8.7611e-03, 5.1675e-03, 4.4174e-03,\n",
       "         3.0698e-01, 5.2813e-01],\n",
       "        [2.2317e-09, 1.2499e-05, 4.3696e-05, 3.7242e-03, 8.5596e-01, 1.4026e-01,\n",
       "         8.8897e-07, 3.1935e-10],\n",
       "        [1.3033e-09, 2.6728e-05, 6.4614e-05, 6.7582e-04, 9.4557e-01, 5.3664e-02,\n",
       "         2.6030e-06, 2.6450e-10],\n",
       "        [4.7089e-07, 1.8304e-03, 3.2749e-03, 4.9139e-03, 8.3877e-01, 1.5119e-01,\n",
       "         1.9811e-05, 3.4899e-08],\n",
       "        [3.0354e-14, 4.2539e-08, 2.3757e-07, 6.9893e-05, 4.4946e-01, 5.5047e-01,\n",
       "         1.1573e-09, 6.9252e-18],\n",
       "        [1.7107e-14, 1.4683e-06, 3.6528e-06, 1.6797e-05, 9.8614e-01, 1.3842e-02,\n",
       "         1.8944e-11, 7.6169e-18],\n",
       "        [7.7890e-02, 2.6847e-01, 2.5766e-02, 1.8822e-02, 5.0797e-01, 3.7285e-03,\n",
       "         7.5313e-02, 2.2033e-02],\n",
       "        [2.7676e-04, 1.7772e-10, 1.7120e-10, 5.0805e-14, 2.2812e-16, 5.3006e-17,\n",
       "         6.9499e-09, 9.9972e-01]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_scores = scores / np.sqrt(U_key.shape[1]) # масштабирование\n",
    "attention_weights = torch.softmax(scaled_scores, dim=-1)  # нормализация с помощью SoftMax\n",
    "attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b8a272d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 8]), torch.Size([8, 16]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights.shape, values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21977e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1060,  0.9678,  1.5669,  1.5762,  1.7334,  0.3509,  2.1180,  1.6764,\n",
       "          1.6418,  0.7886,  1.9459,  1.0276,  1.2672,  1.0364, -0.4764,  0.7733],\n",
       "        [-1.2226, -3.4387, -4.3928, -5.2125, -1.1249, -3.3041, -1.4316, -3.2765,\n",
       "         -2.5114, -2.6105, -1.5793, -2.8433, -2.4142, -0.3998, -1.9917, -3.3499],\n",
       "        [-1.1639, -3.5045, -4.5964, -5.8008, -0.9892, -3.2593, -1.3924, -3.4383,\n",
       "         -2.6604, -2.4408, -1.3912, -2.9849, -2.3546,  0.1087, -2.3330, -3.6736],\n",
       "        [-1.2207, -3.4202, -4.3491, -5.1151, -1.1445, -3.2986, -1.4325, -3.2335,\n",
       "         -2.4892, -2.6230, -1.6025, -2.8163, -2.4199, -0.4728, -1.9363, -3.2950],\n",
       "        [-1.4894, -3.1681, -3.4794, -2.5261, -1.7571, -3.5199, -1.6488, -2.5390,\n",
       "         -1.8424, -3.4175, -2.4575, -2.2117, -2.7089, -2.7630, -0.4126, -1.8831],\n",
       "        [-1.1375, -3.5332, -4.6883, -6.0675, -0.9272, -3.2388, -1.3731, -3.5119,\n",
       "         -2.7275, -2.3628, -1.3052, -3.0486, -2.3267,  0.3408, -2.4886, -3.8200],\n",
       "        [-0.1553, -2.1325, -2.2331, -3.6156, -0.7128, -1.9181, -0.7969, -1.6048,\n",
       "         -2.2524, -1.1594, -1.0006, -1.7255, -1.3452, -0.0157, -1.2998, -2.5547],\n",
       "        [ 1.2704,  2.4613,  2.2501,  3.6259,  2.9113,  0.9841,  3.3068,  2.7711,\n",
       "          3.6286,  1.1094,  3.0604,  2.8248,  1.8339,  1.8976,  0.4261,  1.3637]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_context_vector = attention_weights @ values\n",
    "final_context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "175dca4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98978717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 8]), torch.Size([16, 16]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights.shape, U_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41d5a156",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "d = embedded_sentence.shape[1]\n",
    "one_U_query = torch.rand(d, d)\n",
    "\n",
    "h = 8\n",
    "multihead_U_query = torch.rand(h, d, d)\n",
    "multihead_U_key = torch.rand(h, d, d)\n",
    "multihead_U_value = torch.rand(h, d, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c05ac80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16, 16])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multihead_U_key.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd9016bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9.4053e-01, -4.6806e-01,  1.0322e+00, -2.8300e-01,  4.9275e-01,\n",
       "        -1.4078e-02, -2.7466e-01, -7.6409e-01,  1.3966e+00, -9.9491e-01,\n",
       "        -1.5822e-03,  1.2471e+00, -7.7105e-02,  1.2774e+00, -1.4596e+00,\n",
       "        -2.1595e+00])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d7cc936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16]), torch.Size([8, 16, 16]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mh_q2 = multihead_U_query.matmul(x_2)\n",
    "x_2.shape, multihead_U_query.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5ba22a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2952,  0.5116, -0.5343, -2.1730, -0.5293, -0.4932, -2.0952, -0.5830,\n",
       "         -0.2856,  0.1277,  0.6852, -1.5782, -0.9960, -2.3458, -0.4437, -0.5510],\n",
       "        [ 0.6654, -1.1762,  0.2593, -1.2616, -1.1232, -1.1314, -0.8960, -0.0376,\n",
       "         -3.1714, -0.4293, -1.6761, -0.0262, -0.6826, -0.7709,  0.5206, -2.5693],\n",
       "        [-1.0130,  2.4321, -0.0691, -1.1237, -1.3568,  0.1933, -1.6615, -2.0000,\n",
       "          0.4469, -1.0241, -1.0079, -1.6620, -2.3453, -0.1093, -2.5826, -1.3624],\n",
       "        [ 1.0933, -2.7744, -1.0884, -3.5698,  0.2782, -1.6767, -1.5483,  0.3518,\n",
       "         -1.6836, -0.1056,  0.7932,  0.5691, -1.4224, -0.5437, -1.3615, -1.9626],\n",
       "        [ 0.0784,  0.1832, -1.6212, -0.6045, -2.6574, -0.9026, -1.7585, -1.9547,\n",
       "         -1.8166, -3.3531, -1.9808,  0.5954, -1.2462, -1.1287, -4.5376, -1.2510],\n",
       "        [-0.9583, -0.4244, -1.3361, -0.7831,  0.0427, -0.4317, -0.3390, -0.8504,\n",
       "         -0.9676, -1.1346, -1.1462, -1.2955,  0.3383,  0.7116,  0.5113, -1.7576],\n",
       "        [-2.4430, -1.1740, -3.1078, -0.2340,  0.0777, -0.9694, -0.9922, -0.6035,\n",
       "         -2.0377,  2.1452, -0.8112, -2.4870, -1.3019,  1.3228,  1.5790, -0.0490],\n",
       "        [ 1.3000, -1.3745,  0.9662, -0.9823, -1.2084, -1.1971, -0.0572,  0.7337,\n",
       "         -1.6920, -2.2890, -1.7639, -0.5890, -1.1066, -0.9088, -1.6149, -1.4910]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mh_q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "669c056b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mh_k2 = multihead_U_key.matmul(x_2)\n",
    "mh_v2 = multihead_U_value.matmul(x_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d29d8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_sentence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad4a0aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16, 8])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_sentence.T.repeat(8, 1, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ec68f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(embedded_sentence, embedded_sentence.T.repeat(8, 1, 1)[0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ae6c83ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16, 8])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_sentence.T.repeat(8, 1, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f8eaf7cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4 * 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2169492b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.3737e-01, -1.7778e-01, -3.0353e-01, -5.8801e-01,  3.4861e-01,\n",
       "          6.6034e-01, -2.1964e-01, -3.7917e-01,  7.6711e-01, -1.1925e+00,\n",
       "          6.9835e-01, -1.4097e+00,  1.7938e-01,  1.8951e+00,  4.9545e-01,\n",
       "          2.6920e-01],\n",
       "        [-9.4053e-01, -4.6806e-01,  1.0322e+00, -2.8300e-01,  4.9275e-01,\n",
       "         -1.4078e-02, -2.7466e-01, -7.6409e-01,  1.3966e+00, -9.9491e-01,\n",
       "         -1.5822e-03,  1.2471e+00, -7.7105e-02,  1.2774e+00, -1.4596e+00,\n",
       "         -2.1595e+00],\n",
       "        [-7.7020e-02, -1.0205e+00, -1.6896e-01,  9.1776e-01,  1.5810e+00,\n",
       "          1.3010e+00,  1.2753e+00, -2.0095e-01,  4.9647e-01, -1.5723e+00,\n",
       "          9.6657e-01, -1.1481e+00, -1.1589e+00,  3.2547e-01, -6.3151e-01,\n",
       "         -2.8400e+00],\n",
       "        [-1.3250e+00,  1.7843e-01, -2.1338e+00,  1.0524e+00, -3.8848e-01,\n",
       "         -9.3435e-01, -4.9914e-01, -1.0867e+00,  8.8054e-01,  1.5542e+00,\n",
       "          6.2662e-01, -1.7549e-01,  9.8284e-02, -9.3507e-02,  2.6621e-01,\n",
       "         -5.8504e-01],\n",
       "        [ 2.5529e-01, -5.4963e-01,  1.0042e+00,  8.2723e-01, -3.9481e-01,\n",
       "          4.8923e-01, -2.1681e-01, -1.7472e+00, -1.6025e+00, -1.0764e+00,\n",
       "          9.0315e-01, -7.2184e-01, -5.9508e-01, -7.1122e-01,  6.2296e-01,\n",
       "         -1.3729e+00],\n",
       "        [-2.2150e+00, -1.3193e+00, -2.0915e+00,  9.6285e-01, -3.1861e-02,\n",
       "         -4.7896e-01,  7.6681e-01,  2.7468e-02,  1.9929e+00,  1.3708e+00,\n",
       "         -5.0087e-01, -2.7928e-01, -2.0628e+00,  6.3745e-03, -9.8955e-01,\n",
       "          7.0161e-01],\n",
       "        [ 5.1463e-01,  9.9376e-01, -2.5873e-01, -1.0826e+00, -4.4382e-02,\n",
       "          1.6236e+00, -2.3229e+00,  1.0878e+00,  6.7155e-01,  6.9330e-01,\n",
       "         -9.4872e-01, -7.6507e-02, -1.5264e-01,  1.1674e-01,  4.4026e-01,\n",
       "         -1.4465e+00],\n",
       "        [ 8.7684e-01,  1.6221e+00, -1.4779e+00,  1.1331e+00, -1.2203e+00,\n",
       "          1.3139e+00,  1.0533e+00,  1.3881e-01,  2.2473e+00, -8.0364e-01,\n",
       "         -2.8084e-01,  7.6968e-01, -6.5956e-01, -7.9793e-01,  1.8383e-01,\n",
       "          2.2935e-01]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_sentence.T.repeat(8, 1, 1)[0].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c5f231c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_sentence.T.repeat(8, 1, 1)[0].T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7bafe93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "generator = pipeline('text-generation', model='gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "88b71236",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Hello folks, today is the first time that I have ever written about a game (and not a game about a band like you) that has not been released to the public, so I thought I'd try to share a couple of the early examples of what was happening here.\\n\\nIn the early days, we were all working on the title of a game. Then, after a short time, we decided that we needed to add more content. We had a few ideas, but after a while, we decided that we needed to make an action game. Since the studio wanted to make a game about a band, we had to make an action game.\\n\\nThe story of this game is very similar to the story of any other band. In order to get a band to play, we had to pay a band's license fee. We then had to sign a contract with the studio to make the game. This meant that we had to pay the band's cost, and as we got older, the band had to pay the studio's cost. This was a very large burden, and we had to pay it.\\n\\nIn our project we had to make a game that we could sell to the world. This meant that we had to make a game with three different genres: Action\"},\n",
       " {'generated_text': \"Hello folks, today is the last day of the summer for the 2017-2018 season. We'll also be taking care of our work on the upcoming season of the show (and our own). We think you'll be able to enjoy our show as much as we like.\\n\\nSo, enjoy the show, enjoy the show!\\n\\nWe'll be back again this summer, and we'll see you there!\\n\\nAs always, we welcome you to the website, and thank you for your support of the show.\\n\\nThanks for reading,\\n\\nThe Writers\\n\\nMichael K.\\n\\nThe Script Review Team\"},\n",
       " {'generated_text': \"Hello folks, today is the day we announce the 1.0 stable release.\\n\\nThis means that we have released 1.0. The reason we released 1.0 is because we wanted to keep the following things in mind:\\n\\nThe first thing to note about 1.0 is that we have not updated the client to work with the latest version of Python. The client will still be using the old 2.x standard library, but the latest version of the client will be 1.5.3, which means that the new version of Python will not compile.\\n\\nWe've also made some changes to our build system. We've re-added an auto-detect-test-logger, which will detect the changes in the source code, and will check to see if the change is made by a patch, or by the client's own code.\\n\\nWe've also added a new version of the build system which will allow you to install the 1.0.x release. This means that you can get it while upgrading your Python installation.\\n\\nThe 1.0 release will be available on the 1.0.x site on July 18th, 2017.\\n\\nIf you are new to PyPy or have been waiting for a release, please register\"}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_seed(123)\n",
    "generator('Hello folks, today is', max_length=20, num_return_sequences=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ea8154a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   43,  1039,   514, 37773,   428,  6827]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "text = 'Lets us encode this sentence'\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "encoded_input"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-lessons-gytSFZfn-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
