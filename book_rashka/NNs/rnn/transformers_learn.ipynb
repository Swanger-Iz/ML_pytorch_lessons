{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "103561ee",
   "metadata": {},
   "source": [
    "# Трансформеры обзор и поигрульки с ними"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8820e4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d977a8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 7, 1, 2, 5, 6, 4, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = torch.tensor([0, 7, 1, 2, 5, 6, 4, 3])\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3612c0cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "embed = nn.Embedding(num_embeddings=10, embedding_dim=16)\n",
    "embedded_sentence = embed(sentence).detach()\n",
    "embedded_sentence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b8efaae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9.7601,  1.7326,  4.7543, -1.3587,  0.4752, -1.6717,  1.0227, -0.1286],\n",
       "        [ 1.7326, 16.0787,  9.0642, -0.3370,  1.1368,  1.1972,  1.6485, -1.2789],\n",
       "        [ 4.7543,  9.0642, 22.6615, -0.8519,  7.7799,  2.7483, -0.6832,  1.6236],\n",
       "        [-1.3587, -0.3370, -0.8519, 13.9473, -1.4198, 10.9659, -0.5887,  2.3869],\n",
       "        [ 0.4752,  1.1368,  7.7799, -1.4198, 13.7511, -6.8568, -2.5114, -3.3468],\n",
       "        [-1.6717,  1.1972,  2.7483, 10.9659, -6.8568, 24.6738, -3.8294,  4.9581],\n",
       "        [ 1.0227,  1.6485, -0.6832, -0.5887, -2.5114, -3.8294, 15.8691,  2.0269],\n",
       "        [-0.1286, -1.2789,  1.6236,  2.3869, -3.3468,  4.9581,  2.0269, 18.7382]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omega = torch.empty(8, 8)\n",
    "for i, x_i in enumerate(embedded_sentence):\n",
    "     for j, x_j in enumerate(embedded_sentence):\n",
    "         omega[i, j] = torch.dot(x_i, x_j)\n",
    "omega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad1eeb64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9.7601,  1.7326,  4.7543, -1.3587,  0.4752, -1.6717,  1.0227, -0.1286],\n",
       "        [ 1.7326, 16.0787,  9.0642, -0.3370,  1.1368,  1.1972,  1.6485, -1.2789],\n",
       "        [ 4.7543,  9.0642, 22.6615, -0.8519,  7.7799,  2.7483, -0.6832,  1.6236],\n",
       "        [-1.3587, -0.3370, -0.8519, 13.9473, -1.4198, 10.9659, -0.5887,  2.3869],\n",
       "        [ 0.4752,  1.1368,  7.7799, -1.4198, 13.7511, -6.8568, -2.5114, -3.3468],\n",
       "        [-1.6717,  1.1972,  2.7483, 10.9659, -6.8568, 24.6738, -3.8294,  4.9581],\n",
       "        [ 1.0227,  1.6485, -0.6832, -0.5887, -2.5114, -3.8294, 15.8691,  2.0269],\n",
       "        [-0.1286, -1.2789,  1.6236,  2.3869, -3.3468,  4.9581,  2.0269, 18.7382]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omega_mat = embedded_sentence.matmul(embedded_sentence.T)\n",
    "omega_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec9a7ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(omega, omega_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b22fe35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "attention_weights = F.softmax(omega, dim=1)\n",
    "attention_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48ea3d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33370772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_j: tensor([ 0.3374, -0.1778, -0.3035, -0.5880,  0.3486,  0.6603, -0.2196, -0.3792,\n",
      "         0.7671, -1.1925,  0.6984, -1.4097,  0.1794,  1.8951,  0.4954,  0.2692])\n",
      "context_vec_2: tensor([ 1.9828e-07, -1.0448e-07, -1.7839e-07, -3.4559e-07,  2.0488e-07,\n",
      "         3.8810e-07, -1.2909e-07, -2.2285e-07,  4.5085e-07, -7.0086e-07,\n",
      "         4.1044e-07, -8.2853e-07,  1.0543e-07,  1.1138e-06,  2.9119e-07,\n",
      "         1.5822e-07])\n",
      "x_j: tensor([-9.4053e-01, -4.6806e-01,  1.0322e+00, -2.8300e-01,  4.9275e-01,\n",
      "        -1.4078e-02, -2.7466e-01, -7.6409e-01,  1.3966e+00, -9.9491e-01,\n",
      "        -1.5822e-03,  1.2471e+00, -7.7105e-02,  1.2774e+00, -1.4596e+00,\n",
      "        -2.1595e+00])\n",
      "context_vec_2: tensor([-9.3968e-01, -4.6764e-01,  1.0313e+00, -2.8275e-01,  4.9231e-01,\n",
      "        -1.4065e-02, -2.7442e-01, -7.6340e-01,  1.3953e+00, -9.9402e-01,\n",
      "        -1.5804e-03,  1.2460e+00, -7.7035e-02,  1.2762e+00, -1.4583e+00,\n",
      "        -2.1576e+00])\n",
      "x_j: tensor([-0.0770, -1.0205, -0.1690,  0.9178,  1.5810,  1.3010,  1.2753, -0.2010,\n",
      "         0.4965, -1.5723,  0.9666, -1.1481, -1.1589,  0.3255, -0.6315, -2.8400])\n",
      "context_vec_2: tensor([-9.3975e-01, -4.6856e-01,  1.0311e+00, -2.8192e-01,  4.9373e-01,\n",
      "        -1.2897e-02, -2.7327e-01, -7.6358e-01,  1.3958e+00, -9.9543e-01,\n",
      "        -7.1252e-04,  1.2449e+00, -7.8076e-02,  1.2765e+00, -1.4589e+00,\n",
      "        -2.1601e+00])\n",
      "x_j: tensor([-1.3250,  0.1784, -2.1338,  1.0524, -0.3885, -0.9343, -0.4991, -1.0867,\n",
      "         0.8805,  1.5542,  0.6266, -0.1755,  0.0983, -0.0935,  0.2662, -0.5850])\n",
      "context_vec_2: tensor([-9.3975e-01, -4.6856e-01,  1.0311e+00, -2.8192e-01,  4.9373e-01,\n",
      "        -1.2897e-02, -2.7327e-01, -7.6358e-01,  1.3958e+00, -9.9543e-01,\n",
      "        -7.1247e-04,  1.2449e+00, -7.8076e-02,  1.2765e+00, -1.4589e+00,\n",
      "        -2.1601e+00])\n",
      "x_j: tensor([ 0.2553, -0.5496,  1.0042,  0.8272, -0.3948,  0.4892, -0.2168, -1.7472,\n",
      "        -1.6025, -1.0764,  0.9031, -0.7218, -0.5951, -0.7112,  0.6230, -1.3729])\n",
      "context_vec_2: tensor([-9.3975e-01, -4.6856e-01,  1.0311e+00, -2.8192e-01,  4.9373e-01,\n",
      "        -1.2897e-02, -2.7327e-01, -7.6359e-01,  1.3958e+00, -9.9543e-01,\n",
      "        -7.1218e-04,  1.2449e+00, -7.8076e-02,  1.2765e+00, -1.4589e+00,\n",
      "        -2.1601e+00])\n",
      "x_j: tensor([-2.2150, -1.3193, -2.0915,  0.9629, -0.0319, -0.4790,  0.7668,  0.0275,\n",
      "         1.9929,  1.3708, -0.5009, -0.2793, -2.0628,  0.0064, -0.9896,  0.7016])\n",
      "context_vec_2: tensor([-9.3975e-01, -4.6856e-01,  1.0311e+00, -2.8192e-01,  4.9373e-01,\n",
      "        -1.2897e-02, -2.7327e-01, -7.6359e-01,  1.3958e+00, -9.9543e-01,\n",
      "        -7.1235e-04,  1.2449e+00, -7.8076e-02,  1.2765e+00, -1.4589e+00,\n",
      "        -2.1601e+00])\n",
      "x_j: tensor([ 0.5146,  0.9938, -0.2587, -1.0826, -0.0444,  1.6236, -2.3229,  1.0878,\n",
      "         0.6716,  0.6933, -0.9487, -0.0765, -0.1526,  0.1167,  0.4403, -1.4465])\n",
      "context_vec_2: tensor([-9.3975e-01, -4.6856e-01,  1.0311e+00, -2.8192e-01,  4.9373e-01,\n",
      "        -1.2896e-02, -2.7327e-01, -7.6358e-01,  1.3958e+00, -9.9543e-01,\n",
      "        -7.1287e-04,  1.2449e+00, -7.8077e-02,  1.2765e+00, -1.4589e+00,\n",
      "        -2.1601e+00])\n",
      "x_j: tensor([ 0.8768,  1.6221, -1.4779,  1.1331, -1.2203,  1.3139,  1.0533,  0.1388,\n",
      "         2.2473, -0.8036, -0.2808,  0.7697, -0.6596, -0.7979,  0.1838,  0.2293])\n",
      "context_vec_2: tensor([-9.3975e-01, -4.6856e-01,  1.0311e+00, -2.8192e-01,  4.9373e-01,\n",
      "        -1.2896e-02, -2.7327e-01, -7.6358e-01,  1.3958e+00, -9.9543e-01,\n",
      "        -7.1287e-04,  1.2449e+00, -7.8077e-02,  1.2765e+00, -1.4589e+00,\n",
      "        -2.1601e+00])\n"
     ]
    }
   ],
   "source": [
    "x_2 = embedded_sentence[1, :]\n",
    "context_vec_2 = torch.zeros(x_2.shape)\n",
    "for j in range(8):\n",
    "    x_j = embedded_sentence[j, :]\n",
    "    print('x_j:', x_j)\n",
    "    context_vec_2 += attention_weights[1, j] * x_j\n",
    "    print('context_vec_2:', context_vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81c9e3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.3420e-01, -1.8324e-01, -3.0218e-01, -5.7772e-01,  3.5662e-01,\n",
       "          6.6452e-01, -2.0998e-01, -3.7798e-01,  7.6537e-01, -1.1946e+00,\n",
       "          6.9960e-01, -1.4067e+00,  1.7021e-01,  1.8838e+00,  4.8729e-01,\n",
       "          2.4730e-01],\n",
       "        [-9.3975e-01, -4.6856e-01,  1.0311e+00, -2.8192e-01,  4.9373e-01,\n",
       "         -1.2896e-02, -2.7327e-01, -7.6358e-01,  1.3958e+00, -9.9543e-01,\n",
       "         -7.1287e-04,  1.2449e+00, -7.8077e-02,  1.2765e+00, -1.4589e+00,\n",
       "         -2.1601e+00],\n",
       "        [-7.7021e-02, -1.0205e+00, -1.6895e-01,  9.1776e-01,  1.5810e+00,\n",
       "          1.3010e+00,  1.2753e+00, -2.0095e-01,  4.9647e-01, -1.5723e+00,\n",
       "          9.6657e-01, -1.1481e+00, -1.1589e+00,  3.2547e-01, -6.3151e-01,\n",
       "         -2.8400e+00],\n",
       "        [-1.3679e+00,  1.0614e-01, -2.1317e+00,  1.0480e+00, -3.7127e-01,\n",
       "         -9.1234e-01, -4.3802e-01, -1.0329e+00,  9.3425e-01,  1.5453e+00,\n",
       "          5.7218e-01, -1.8049e-01, -6.0453e-03, -8.8691e-02,  2.0559e-01,\n",
       "         -5.2292e-01],\n",
       "        [ 2.5444e-01, -5.5082e-01,  1.0012e+00,  8.2746e-01, -3.8978e-01,\n",
       "          4.9129e-01, -2.1302e-01, -1.7432e+00, -1.5972e+00, -1.0776e+00,\n",
       "          9.0331e-01, -7.2292e-01, -5.9652e-01, -7.0857e-01,  6.1977e-01,\n",
       "         -1.3766e+00],\n",
       "        [-2.2150e+00, -1.3193e+00, -2.0915e+00,  9.6285e-01, -3.1862e-02,\n",
       "         -4.7896e-01,  7.6681e-01,  2.7467e-02,  1.9929e+00,  1.3708e+00,\n",
       "         -5.0087e-01, -2.7928e-01, -2.0628e+00,  6.3744e-03, -9.8955e-01,\n",
       "          7.0161e-01],\n",
       "        [ 5.1463e-01,  9.9376e-01, -2.5873e-01, -1.0825e+00, -4.4383e-02,\n",
       "          1.6236e+00, -2.3229e+00,  1.0878e+00,  6.7156e-01,  6.9329e-01,\n",
       "         -9.4872e-01, -7.6506e-02, -1.5264e-01,  1.1674e-01,  4.4026e-01,\n",
       "         -1.4465e+00],\n",
       "        [ 8.7683e-01,  1.6221e+00, -1.4779e+00,  1.1331e+00, -1.2203e+00,\n",
       "          1.3139e+00,  1.0533e+00,  1.3880e-01,  2.2473e+00, -8.0363e-01,\n",
       "         -2.8084e-01,  7.6967e-01, -6.5956e-01, -7.9793e-01,  1.8383e-01,\n",
       "          2.2935e-01]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vectors = torch.matmul(attention_weights, embedded_sentence)\n",
    "context_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26060d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(context_vectors[1], context_vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2c0a9c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "d = embedded_sentence.shape[1]\n",
    "U_query = torch.rand(d, d)\n",
    "U_key = torch.rand(d, d)\n",
    "U_value = torch.rand(d, d)\n",
    "\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "329108e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-1.2403, -2.9754, -0.2894, -0.4004, -2.9578, -0.2939, -0.2266, -3.6482,\n",
       "         -2.6450, -0.9536, -1.1116,  1.1717, -2.2671, -0.7874, -2.0140, -1.6652]),\n",
       " torch.Size([16]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_2 = embedded_sentence[1]\n",
    "query_2 = U_query.matmul(x_2)\n",
    "query_2, query_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdb99ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-1.2952,  0.5116, -0.5343, -2.1730, -0.5293, -0.4932, -2.0952, -0.5830,\n",
       "         -0.2856,  0.1277,  0.6852, -1.5782, -0.9960, -2.3458, -0.4437, -0.5510]),\n",
       " tensor([ 0.6654, -1.1762,  0.2593, -1.2616, -1.1232, -1.1314, -0.8960, -0.0376,\n",
       "         -3.1714, -0.4293, -1.6761, -0.0262, -0.6826, -0.7709,  0.5206, -2.5693]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_2 = U_key.matmul(x_2)\n",
    "value_2 = U_value.matmul(x_2)\n",
    "key_2, value_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44fa2df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7665, -1.1306,  0.0167,  1.3456, -0.0111,  0.2577,  0.3018,  0.5771,\n",
       "          0.8287, -0.3224,  0.9979, -1.3807,  0.7953,  0.3018,  1.1813,  1.3559],\n",
       "        [-1.2403, -2.9754, -0.2894, -0.4004, -2.9578, -0.2939, -0.2266, -3.6482,\n",
       "         -2.6450, -0.9536, -1.1116,  1.1717, -2.2671, -0.7874, -2.0140, -1.6652],\n",
       "        [-1.4620, -2.9039, -2.9815,  0.1616, -1.7143, -3.4239, -1.4447, -2.2414,\n",
       "         -3.0720, -3.0587,  1.1979,  0.2866, -0.5552, -0.0643, -1.3262, -0.3223],\n",
       "        [ 0.0758, -1.2134, -2.7353, -1.2504, -2.3630, -1.7872, -2.4223, -1.3309,\n",
       "          0.0371,  0.4128, -0.2362, -1.7722, -0.9576, -0.6908, -1.9191, -0.0077],\n",
       "        [-1.0274, -3.9126, -2.1115, -1.1729, -2.0862, -4.8391, -1.5899, -2.5706,\n",
       "         -3.0113, -3.2927, -4.0568, -0.3453, -3.0388, -2.1831, -2.6464, -2.5228],\n",
       "        [-0.6838, -2.4960, -4.3936, -3.7471, -2.7305, -2.1619, -5.9295, -3.5328,\n",
       "         -1.5616,  0.2982, -0.4995, -2.9656, -1.4150, -1.2241, -2.2443, -2.1584],\n",
       "        [ 0.8982,  0.1030,  0.4428,  0.6328, -1.7003,  1.3489, -0.3082, -0.5900,\n",
       "         -0.9257, -0.7688,  1.8828, -1.6065, -0.8011, -0.4114, -0.6116,  1.3902],\n",
       "        [ 2.9258,  2.5598,  2.3612,  0.9851,  3.3478,  2.5134,  1.4786,  2.4595,\n",
       "          3.2942,  2.1628,  4.1394,  0.7536,  2.8714,  3.5802, -0.2554,  2.9326]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = embedded_sentence.matmul(U_query.T)\n",
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "831c91ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys1 = U_key.matmul(embedded_sentence.T).T\n",
    "values1 = U_value.matmul(embedded_sentence.T).T\n",
    "# print(keys, values)\n",
    "\n",
    "keys = embedded_sentence.matmul(U_key.T)  # embedded_sentence (L, d), U_value (16x16), для перемножения нужно чтобы было (16хА) и (Ах8)\n",
    "values = embedded_sentence.matmul(U_value.T)\n",
    "torch.allclose(keys1, keys), torch.allclose(values1, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de521d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09983b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -0.7569,  -3.7951,  -7.9465, -10.0615, -12.1732, -12.8006,   4.1644,\n",
       "           6.3346],\n",
       "        [-25.1623,   9.3602,  14.3667,  32.1482,  53.8976,  46.6626,  -1.2131,\n",
       "         -32.9392],\n",
       "        [-28.8096,  10.9046,  14.4355,  23.8255,  52.7999,  41.3237,   1.5884,\n",
       "         -35.1890],\n",
       "        [-15.5115,  17.5500,  19.8771,  21.5002,  42.0597,  35.2061,  -0.5541,\n",
       "         -25.9203],\n",
       "        [-36.3682,  20.2438,  27.1240,  49.8610,  84.9364,  85.7472,   5.8265,\n",
       "         -69.9103],\n",
       "        [-34.6901,  38.3814,  42.0269,  48.1298,  92.0512,  74.9869,  -6.6510,\n",
       "         -65.5576],\n",
       "        [ -1.1880,   3.7619,  -5.6129,  -6.8690,   6.3126, -13.3452,  -1.3225,\n",
       "          -6.2390],\n",
       "        [ 31.8297, -25.2041, -25.3536, -57.8440, -79.4676, -85.3054, -10.5390,\n",
       "          64.5980]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = queries @ keys.T\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5bacf7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8.9701e-02, 4.1968e-02, 1.4866e-02, 8.7611e-03, 5.1675e-03, 4.4174e-03,\n",
       "         3.0698e-01, 5.2813e-01],\n",
       "        [2.2317e-09, 1.2499e-05, 4.3696e-05, 3.7242e-03, 8.5596e-01, 1.4026e-01,\n",
       "         8.8897e-07, 3.1935e-10],\n",
       "        [1.3033e-09, 2.6728e-05, 6.4614e-05, 6.7582e-04, 9.4557e-01, 5.3664e-02,\n",
       "         2.6030e-06, 2.6450e-10],\n",
       "        [4.7089e-07, 1.8304e-03, 3.2749e-03, 4.9139e-03, 8.3877e-01, 1.5119e-01,\n",
       "         1.9811e-05, 3.4899e-08],\n",
       "        [3.0354e-14, 4.2539e-08, 2.3757e-07, 6.9893e-05, 4.4946e-01, 5.5047e-01,\n",
       "         1.1573e-09, 6.9252e-18],\n",
       "        [1.7107e-14, 1.4683e-06, 3.6528e-06, 1.6797e-05, 9.8614e-01, 1.3842e-02,\n",
       "         1.8944e-11, 7.6169e-18],\n",
       "        [7.7890e-02, 2.6847e-01, 2.5766e-02, 1.8822e-02, 5.0797e-01, 3.7285e-03,\n",
       "         7.5313e-02, 2.2033e-02],\n",
       "        [2.7676e-04, 1.7772e-10, 1.7120e-10, 5.0805e-14, 2.2812e-16, 5.3006e-17,\n",
       "         6.9499e-09, 9.9972e-01]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_scores = scores / np.sqrt(U_key.shape[1]) # масштабирование\n",
    "attention_weights = torch.softmax(scaled_scores, dim=-1)  # нормализация с помощью SoftMax\n",
    "attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b8a272d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 8]), torch.Size([8, 16]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights.shape, values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21977e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1060,  0.9678,  1.5669,  1.5762,  1.7334,  0.3509,  2.1180,  1.6764,\n",
       "          1.6418,  0.7886,  1.9459,  1.0276,  1.2672,  1.0364, -0.4764,  0.7733],\n",
       "        [-1.2226, -3.4387, -4.3928, -5.2125, -1.1249, -3.3041, -1.4316, -3.2765,\n",
       "         -2.5114, -2.6105, -1.5793, -2.8433, -2.4142, -0.3998, -1.9917, -3.3499],\n",
       "        [-1.1639, -3.5045, -4.5964, -5.8008, -0.9892, -3.2593, -1.3924, -3.4383,\n",
       "         -2.6604, -2.4408, -1.3912, -2.9849, -2.3546,  0.1087, -2.3330, -3.6736],\n",
       "        [-1.2207, -3.4202, -4.3491, -5.1151, -1.1445, -3.2986, -1.4325, -3.2335,\n",
       "         -2.4892, -2.6230, -1.6025, -2.8163, -2.4199, -0.4728, -1.9363, -3.2950],\n",
       "        [-1.4894, -3.1681, -3.4794, -2.5261, -1.7571, -3.5199, -1.6488, -2.5390,\n",
       "         -1.8424, -3.4175, -2.4575, -2.2117, -2.7089, -2.7630, -0.4126, -1.8831],\n",
       "        [-1.1375, -3.5332, -4.6883, -6.0675, -0.9272, -3.2388, -1.3731, -3.5119,\n",
       "         -2.7275, -2.3628, -1.3052, -3.0486, -2.3267,  0.3408, -2.4886, -3.8200],\n",
       "        [-0.1553, -2.1325, -2.2331, -3.6156, -0.7128, -1.9181, -0.7969, -1.6048,\n",
       "         -2.2524, -1.1594, -1.0006, -1.7255, -1.3452, -0.0157, -1.2998, -2.5547],\n",
       "        [ 1.2704,  2.4613,  2.2501,  3.6259,  2.9113,  0.9841,  3.3068,  2.7711,\n",
       "          3.6286,  1.1094,  3.0604,  2.8248,  1.8339,  1.8976,  0.4261,  1.3637]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_context_vector = attention_weights @ values\n",
    "final_context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "175dca4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98978717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 8]), torch.Size([16, 16]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights.shape, U_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41d5a156",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "d = embedded_sentence.shape[1]\n",
    "one_U_query = torch.rand(d, d)\n",
    "\n",
    "h = 8\n",
    "multihead_U_query = torch.rand(h, d, d)\n",
    "multihead_U_key = torch.rand(h, d, d)\n",
    "multihead_U_value = torch.rand(h, d, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c05ac80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16, 16])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multihead_U_key.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd9016bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9.4053e-01, -4.6806e-01,  1.0322e+00, -2.8300e-01,  4.9275e-01,\n",
       "        -1.4078e-02, -2.7466e-01, -7.6409e-01,  1.3966e+00, -9.9491e-01,\n",
       "        -1.5822e-03,  1.2471e+00, -7.7105e-02,  1.2774e+00, -1.4596e+00,\n",
       "        -2.1595e+00])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d7cc936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16]), torch.Size([8, 16, 16]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mh_q2 = multihead_U_query.matmul(x_2)\n",
    "x_2.shape, multihead_U_query.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5ba22a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2952,  0.5116, -0.5343, -2.1730, -0.5293, -0.4932, -2.0952, -0.5830,\n",
       "         -0.2856,  0.1277,  0.6852, -1.5782, -0.9960, -2.3458, -0.4437, -0.5510],\n",
       "        [ 0.6654, -1.1762,  0.2593, -1.2616, -1.1232, -1.1314, -0.8960, -0.0376,\n",
       "         -3.1714, -0.4293, -1.6761, -0.0262, -0.6826, -0.7709,  0.5206, -2.5693],\n",
       "        [-1.0130,  2.4321, -0.0691, -1.1237, -1.3568,  0.1933, -1.6615, -2.0000,\n",
       "          0.4469, -1.0241, -1.0079, -1.6620, -2.3453, -0.1093, -2.5826, -1.3624],\n",
       "        [ 1.0933, -2.7744, -1.0884, -3.5698,  0.2782, -1.6767, -1.5483,  0.3518,\n",
       "         -1.6836, -0.1056,  0.7932,  0.5691, -1.4224, -0.5437, -1.3615, -1.9626],\n",
       "        [ 0.0784,  0.1832, -1.6212, -0.6045, -2.6574, -0.9026, -1.7585, -1.9547,\n",
       "         -1.8166, -3.3531, -1.9808,  0.5954, -1.2462, -1.1287, -4.5376, -1.2510],\n",
       "        [-0.9583, -0.4244, -1.3361, -0.7831,  0.0427, -0.4317, -0.3390, -0.8504,\n",
       "         -0.9676, -1.1346, -1.1462, -1.2955,  0.3383,  0.7116,  0.5113, -1.7576],\n",
       "        [-2.4430, -1.1740, -3.1078, -0.2340,  0.0777, -0.9694, -0.9922, -0.6035,\n",
       "         -2.0377,  2.1452, -0.8112, -2.4870, -1.3019,  1.3228,  1.5790, -0.0490],\n",
       "        [ 1.3000, -1.3745,  0.9662, -0.9823, -1.2084, -1.1971, -0.0572,  0.7337,\n",
       "         -1.6920, -2.2890, -1.7639, -0.5890, -1.1066, -0.9088, -1.6149, -1.4910]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mh_q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "669c056b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mh_k2 = multihead_U_key.matmul(x_2)\n",
    "mh_v2 = multihead_U_value.matmul(x_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d29d8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_sentence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad4a0aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16, 8])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_sentence.T.repeat(8, 1, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ec68f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(embedded_sentence, embedded_sentence.T.repeat(8, 1, 1)[0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ae6c83ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16, 8])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_sentence.T.repeat(8, 1, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f8eaf7cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4 * 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2169492b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.3737e-01, -1.7778e-01, -3.0353e-01, -5.8801e-01,  3.4861e-01,\n",
       "          6.6034e-01, -2.1964e-01, -3.7917e-01,  7.6711e-01, -1.1925e+00,\n",
       "          6.9835e-01, -1.4097e+00,  1.7938e-01,  1.8951e+00,  4.9545e-01,\n",
       "          2.6920e-01],\n",
       "        [-9.4053e-01, -4.6806e-01,  1.0322e+00, -2.8300e-01,  4.9275e-01,\n",
       "         -1.4078e-02, -2.7466e-01, -7.6409e-01,  1.3966e+00, -9.9491e-01,\n",
       "         -1.5822e-03,  1.2471e+00, -7.7105e-02,  1.2774e+00, -1.4596e+00,\n",
       "         -2.1595e+00],\n",
       "        [-7.7020e-02, -1.0205e+00, -1.6896e-01,  9.1776e-01,  1.5810e+00,\n",
       "          1.3010e+00,  1.2753e+00, -2.0095e-01,  4.9647e-01, -1.5723e+00,\n",
       "          9.6657e-01, -1.1481e+00, -1.1589e+00,  3.2547e-01, -6.3151e-01,\n",
       "         -2.8400e+00],\n",
       "        [-1.3250e+00,  1.7843e-01, -2.1338e+00,  1.0524e+00, -3.8848e-01,\n",
       "         -9.3435e-01, -4.9914e-01, -1.0867e+00,  8.8054e-01,  1.5542e+00,\n",
       "          6.2662e-01, -1.7549e-01,  9.8284e-02, -9.3507e-02,  2.6621e-01,\n",
       "         -5.8504e-01],\n",
       "        [ 2.5529e-01, -5.4963e-01,  1.0042e+00,  8.2723e-01, -3.9481e-01,\n",
       "          4.8923e-01, -2.1681e-01, -1.7472e+00, -1.6025e+00, -1.0764e+00,\n",
       "          9.0315e-01, -7.2184e-01, -5.9508e-01, -7.1122e-01,  6.2296e-01,\n",
       "         -1.3729e+00],\n",
       "        [-2.2150e+00, -1.3193e+00, -2.0915e+00,  9.6285e-01, -3.1861e-02,\n",
       "         -4.7896e-01,  7.6681e-01,  2.7468e-02,  1.9929e+00,  1.3708e+00,\n",
       "         -5.0087e-01, -2.7928e-01, -2.0628e+00,  6.3745e-03, -9.8955e-01,\n",
       "          7.0161e-01],\n",
       "        [ 5.1463e-01,  9.9376e-01, -2.5873e-01, -1.0826e+00, -4.4382e-02,\n",
       "          1.6236e+00, -2.3229e+00,  1.0878e+00,  6.7155e-01,  6.9330e-01,\n",
       "         -9.4872e-01, -7.6507e-02, -1.5264e-01,  1.1674e-01,  4.4026e-01,\n",
       "         -1.4465e+00],\n",
       "        [ 8.7684e-01,  1.6221e+00, -1.4779e+00,  1.1331e+00, -1.2203e+00,\n",
       "          1.3139e+00,  1.0533e+00,  1.3881e-01,  2.2473e+00, -8.0364e-01,\n",
       "         -2.8084e-01,  7.6968e-01, -6.5956e-01, -7.9793e-01,  1.8383e-01,\n",
       "          2.2935e-01]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_sentence.T.repeat(8, 1, 1)[0].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c5f231c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_sentence.T.repeat(8, 1, 1)[0].T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7bafe93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "generator = pipeline('text-generation', model='gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "88b71236",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Hello folks, today is the first time that I have ever written about a game (and not a game about a band like you) that has not been released to the public, so I thought I'd try to share a couple of the early examples of what was happening here.\\n\\nIn the early days, we were all working on the title of a game. Then, after a short time, we decided that we needed to add more content. We had a few ideas, but after a while, we decided that we needed to make an action game. Since the studio wanted to make a game about a band, we had to make an action game.\\n\\nThe story of this game is very similar to the story of any other band. In order to get a band to play, we had to pay a band's license fee. We then had to sign a contract with the studio to make the game. This meant that we had to pay the band's cost, and as we got older, the band had to pay the studio's cost. This was a very large burden, and we had to pay it.\\n\\nIn our project we had to make a game that we could sell to the world. This meant that we had to make a game with three different genres: Action\"},\n",
       " {'generated_text': \"Hello folks, today is the last day of the summer for the 2017-2018 season. We'll also be taking care of our work on the upcoming season of the show (and our own). We think you'll be able to enjoy our show as much as we like.\\n\\nSo, enjoy the show, enjoy the show!\\n\\nWe'll be back again this summer, and we'll see you there!\\n\\nAs always, we welcome you to the website, and thank you for your support of the show.\\n\\nThanks for reading,\\n\\nThe Writers\\n\\nMichael K.\\n\\nThe Script Review Team\"},\n",
       " {'generated_text': \"Hello folks, today is the day we announce the 1.0 stable release.\\n\\nThis means that we have released 1.0. The reason we released 1.0 is because we wanted to keep the following things in mind:\\n\\nThe first thing to note about 1.0 is that we have not updated the client to work with the latest version of Python. The client will still be using the old 2.x standard library, but the latest version of the client will be 1.5.3, which means that the new version of Python will not compile.\\n\\nWe've also made some changes to our build system. We've re-added an auto-detect-test-logger, which will detect the changes in the source code, and will check to see if the change is made by a patch, or by the client's own code.\\n\\nWe've also added a new version of the build system which will allow you to install the 1.0.x release. This means that you can get it while upgrading your Python installation.\\n\\nThe 1.0 release will be available on the 1.0.x site on July 18th, 2017.\\n\\nIf you are new to PyPy or have been waiting for a release, please register\"}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_seed(123)\n",
    "generator('Hello folks, today is', max_length=20, num_return_sequences=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ea8154a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   43,  1039,   514, 37773,   428,  6827]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "text = 'Lets us encode this sentence'\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "encoded_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5926ca90",
   "metadata": {},
   "source": [
    "# Тонкая настройка модели BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b6af16",
   "metadata": {},
   "source": [
    "## Подготовка и загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec153c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilgiz/.cache/pypoetry/virtualenvs/ml-lessons-gytSFZfn-py3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "# import tourchtextx\n",
    "\n",
    "import transformers\n",
    "from transformers import DistilBertTokenizerFast\n",
    "from transformers import DistilBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d386f5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "RANDOM_SEED = 123\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfbd4150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = (\"https://github.com/rasbt/machine-learning-book/raw/main/ch08/movie_data.csv.gz\")\n",
    "# filename = url.split(\"/\")[-1]\n",
    "# filename\n",
    "\n",
    "import os\n",
    "import io\n",
    "\n",
    "root_dir = 'datasets/aclImdb'\n",
    "\n",
    "def load_amdb_ds(root_dir, split):\n",
    "    \n",
    "    labels = {'neg': 0, 'pos': 1}\n",
    "    out_data = []\n",
    "    out_labels = []\n",
    "    \n",
    "    for label_name, label_id in labels.items():\n",
    "        folder_path = os.path.join(root_dir, split, label_name)\n",
    "        \n",
    "        if not os.path.exists(folder_path): continue\n",
    "        \n",
    "        for file_name in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            \n",
    "            with io.open(file_path, 'r', encoding='utf-8') as f:\n",
    "                review = f.read()\n",
    "                out_labels.append(label_id)\n",
    "                out_data.append(review)\n",
    "    return out_data, out_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c54024c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw_data, train_raw_labels = load_amdb_ds(root_dir, 'train')\n",
    "train_raw_data = pd.Series(train_raw_data)\n",
    "train_raw_labels = pd.Series(train_raw_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8ea0391",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_raw_data, test_raw_labels = load_amdb_ds(root_dir, 'test')\n",
    "test_raw_data = pd.Series(test_raw_data)\n",
    "test_raw_labels = pd.Series(test_raw_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43043d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000,), (25000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw_data.shape, test_raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c00e7974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Actually, the movie is neither horror nor Sci-...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is loosely based on the ideas of the orig...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dreyfuss plays a mob boss who lost his mind, b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I think \"The Best of Times\" was a lost cause f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John Candy. Need we say more? He is the main r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>Someone release this movie on DVD so it can ta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>I am amazed at how this movie(and most others ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>Normally I try to avoid Sci-Fi movies as much ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>Masters of Horror: Right to Die starts late on...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>Not many reviews, hence thought i would add on...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "0      Actually, the movie is neither horror nor Sci-...          0\n",
       "1      This is loosely based on the ideas of the orig...          0\n",
       "2      Dreyfuss plays a mob boss who lost his mind, b...          0\n",
       "3      I think \"The Best of Times\" was a lost cause f...          0\n",
       "4      John Candy. Need we say more? He is the main r...          0\n",
       "...                                                  ...        ...\n",
       "24995  Someone release this movie on DVD so it can ta...          1\n",
       "24996  I am amazed at how this movie(and most others ...          1\n",
       "24997  Normally I try to avoid Sci-Fi movies as much ...          1\n",
       "24998  Masters of Horror: Right to Die starts late on...          1\n",
       "24999  Not many reviews, hence thought i would add on...          1\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.concat([train_raw_data, train_raw_labels], axis=1)\n",
    "train_df = train_df.rename(columns={0:'review', 1: 'sentiment'})\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9953b0bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>For a movie that was the most seen in its nati...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OK, it's a piece of historical film making tha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ghost Story has an interesting feminist reveng...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gargoyle starts late one night in 'Romania 153...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>First of all, I think the casting and acting w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>Have just seen the last episode, No 32, (thoug...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>This film has some rather shocking scenes and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>This movie is hilarious. The laughs never stop...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>Not much to it but a validation of small town ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>It has very little to do with the books: half ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "0      For a movie that was the most seen in its nati...          0\n",
       "1      OK, it's a piece of historical film making tha...          0\n",
       "2      Ghost Story has an interesting feminist reveng...          0\n",
       "3      Gargoyle starts late one night in 'Romania 153...          0\n",
       "4      First of all, I think the casting and acting w...          0\n",
       "...                                                  ...        ...\n",
       "24995  Have just seen the last episode, No 32, (thoug...          1\n",
       "24996  This film has some rather shocking scenes and ...          1\n",
       "24997  This movie is hilarious. The laughs never stop...          1\n",
       "24998  Not much to it but a validation of small town ...          1\n",
       "24999  It has very little to do with the books: half ...          1\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.concat([test_raw_data, test_raw_labels], axis=1)\n",
    "test_df = test_df.rename(columns={0:'review', 1: 'sentiment'})\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0528011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35000.0, 10000.0, 5000.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Размеры датасетов. train, validate, test\n",
    "50000 * .7, 50000 * .2, 50000 * .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8474b98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_df, test_df.iloc[:10000]], axis=0, ignore_index=True)\n",
    "valid_df = test_df.iloc[10000:]\n",
    "test_df = test_df.iloc[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f035706f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 2), (15000, 2), (5000, 2))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, valid_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd347565",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = train_df.review.values\n",
    "train_labels = train_df.sentiment.values\n",
    "\n",
    "valid_texts = valid_df.review.values\n",
    "valid_labels = valid_df.sentiment.values\n",
    "\n",
    "test_texts = test_df.review.values\n",
    "test_labels = test_df.sentiment.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daf6cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_raw_data, train_raw_labels\n",
    "del train_df, valid_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725d7a39",
   "metadata": {},
   "source": [
    "## Токенизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c14101db",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4abec34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True)\n",
    "valid_encodings = tokenizer(list(valid_texts), truncation=True, padding=True)\n",
    "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36aed224",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMBD_ds(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        item = {key: torch.tensor(val[index]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[index])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "948c319a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = IMBD_ds(train_encodings, train_labels)\n",
    "valid_ds = IMBD_ds(valid_encodings, valid_labels)\n",
    "test_ds = IMBD_ds(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc1a7f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "valid_dl = torch.utils.data.DataLoader(test_ds, batch_size=16, shuffle=True)\n",
    "test_dl = torch.utils.data.DataLoader(valid_ds, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7408541",
   "metadata": {},
   "source": [
    "## Загрузка и тонкая настройка предварительно обученной модели BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9b2843d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9d38a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
    "model.to(DEVICE)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad7e95aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8e44a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, data_loader, device):\n",
    "    with torch.no_grad():\n",
    "        correct_pred, num_examples = 0, 0\n",
    "        \n",
    "        for batch_idx, batch in enumerate(data_loader):\n",
    "            ### Подготовка данных\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs['logits']\n",
    "            predicted_labels = torch.argmax(logits, 1)\n",
    "            num_examples += labels.size(0)\n",
    "            correct_pred += (predicted_labels == labels).sum()\n",
    "        \n",
    "        return correct_pred.float() / num_examples * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d817330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036f8662",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 3\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    for batch_idx, batch in enumerate(train_dl):\n",
    "        \n",
    "        ### Подготовка данных\n",
    "        input_ids = batch['input_ids'].to(DEVICE)\n",
    "        attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "        labels = batch['labels'].to(DEVICE)\n",
    "        \n",
    "        ### Прямой проход\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss, logits = outputs['loss'], outputs['logits']\n",
    "        \n",
    "        ### Обратный проход\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        ### Логгирование\n",
    "        if not batch_idx % 250:\n",
    "            print(f\"Epoch: {epoch+1:04d}/{NUM_EPOCHS:04d} | batch: {batch_idx:04d}/{len(batch_idx):04d} | loss: {loss:.4f}\")\n",
    "            \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.set_grad_enabled(False):\n",
    "        print(f\"Train accuracy: {compute_accuracy(model, train_dl, DEVICE):.2f}% | Validation accuracy: {compute_accuracy(model, valid_dl, DEVICE):.2f}%\")\n",
    "    \n",
    "    print(f'Time passed: {(time.time() - start_time) / 60:.2f} min')\n",
    "\n",
    "print(f'Final training time: {(time.time() - start_time) / 60:.2f} min')\n",
    "print(f\"Test accuracy: {compute_accuracy(model, train_dl, DEVICE):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de04aac",
   "metadata": {},
   "source": [
    "## Удобная обучение с помощью API-Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cf96af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
    "model.to(DEVICE)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2f1e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc5c2e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e736fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir='./result', num_train_epochs=3, per_device_train_batch_size=16, per_device_eval_batch_size=16, logging_dir='./logs', logging_steps=10)\n",
    "\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=train_ds, optimizers=(optim, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711d8800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проблема в том, что при обучении модель показывает потери только для обучающего набора данных, чтобы обойти эту проблему нужно создать ф-цию, которая будет подсчитывать метрики, куда отправим train и valid данные\n",
    "\n",
    "from datasets import load_metric\n",
    "import numpy as np\n",
    "\n",
    "metric = load_metric('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3d3a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    \n",
    "    # ВАЖНО logits - это numpy массив, а не тензор\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfd37a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# обновленный экземпляр Trainer\n",
    "\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=train_ds, eval_dataset=test_ds, compute_metrics=compute_metrics, optimizers=(optim, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42923519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# обучение\n",
    "start_time = time.time()\n",
    "trainer.train()\n",
    "\n",
    "print(f'Full learning time: {start_time - time.time():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090de2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оценка\n",
    "print(trainer.evaluate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cf20d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Напрямую оцениваем точность модели\n",
    "model.eval()\n",
    "model.to(DEVICE)\n",
    "\n",
    "print(f'Testing accuracy: {compute_accuracy(model, test_dl, DEVICE):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e334a9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если нужно регулярно смотреть точность модели\n",
    "# training_args = TrainingArguments('test_trainer', evluation_strategy='epoch', ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8319e446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если нужно будет поменять гиперпараметры и обучить несколько раз, то лучше использовать валидационный набор данных для избежания утечки информации\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=valid_ds,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-lessons-gytSFZfn-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
